{
    "ziv0-gam-fund-commentary": [
        {
            "url": "https://rbcgithub.fg.rbc.com/rbc-to/ziv0-gam-fund-commentary/pull/62",
            "title": "Optimize Workflows",
            "description": "### Task Descriptions\r\n\r\n- Optimize CrewAI workflow for the expand content agent to only pass the information necessary to complete the task\r\n- Optimize CrewAI workflow for the fact check gpt researcher agent to only pass the information necessary to complete the task\r\n- Optimize CrewAI workflow for the fact check attribution table agent to only pass the information necessary to complete the task\r\n\r\n### Solution Descriptions\r\n\r\n#### Expand Content Agent\r\n\r\nThe expand content agent should only take in the sentence and paragraph needed, as opposed to the whole comment. Therefore, when the expand_sentence function is called on the commentary, it now takes in a request in tuple format alongside the commentary. The request tuple specifies the paragraph and sentence number, which allows us to feed the agent only the sentence that needs to be expanded and the paragraph that sentence is in.\r\n\r\nAs our sentences are annotated, and the expanded sentence is returned as plain text, we split the expanded sentence up into different sentences and add the same annotations as were originally given. This means we are assuming the companies, sectors, key_drivers, etc. related to the expanded sentences are the same as those related to the original sentence. \r\n\r\n#### Fact Check \r\n\r\nInitially, research fact check was called on sentences by the HeadFactCheckCrew. This was problematic, as sometimes a sentence contains multiple claims, some of which are better suited for a data fact check. Therefore, we now have a dedicated crew for splitting sentences up into multiple claims. A separate crew was needed as the HeadFactCheckCrew will essentially need this crew's output as its input. There seems to be no other way for handling this with CrewAI.\r\n\r\nAs sentences are split into smaller claims, I have adjusted various minor parts of get_researcher (such as number of queries generated, number of urls used, etc.) in an attempt to improve speed. Currently, it seems to take 2.5 minutes to research a single claim within a sentence. As Jessica was hoping for a 1-minute wait time, this means we should considering working on optimizing fact check in future sprints.\r\n\r\n#### Data Fact Check\r\n\r\nFor data fact checking, we were previously passing in the full fund data, when only certain parts of it will be used. Therefore, I have introduced a function get_relevant_data which assumes certain sentence annotations, and uses these to extract key parts of the JSON performance data. When run_fact_check is called, it uses this get_relevant_data function to make sure only necessary data is given to the agents. This significantly improves speed.\r\n\r\n### Testing Information\r\n\r\nIn the main file, I have included example inputs for each of the functions I have changed. In the test directory, I have added unit tests where possible. As a lot of the code is non-deterministic, the focus is mainly on confirming output formats are as expected.",
            "state": "closed",
            "created_at": "2024-09-18T16:28:26+00:00",
            "updated_at": "2025-03-07T13:48:44+00:00",
            "comments": []
        }
    ]
}